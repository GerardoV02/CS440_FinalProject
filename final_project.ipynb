{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dxazwwhezoy"
      },
      "source": [
        "# NLBSE Code Comment Classification\n",
        "\n",
        "This is our attempt at modeling the code comment classificaiton problem through the NLBSE '25 challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m-yG2fiumOo"
      },
      "source": [
        "@article{rani2021,\n",
        "                title={How to identify class comment types? A multi-language approach for class comment classification},\n",
        "                author={Rani, Pooja and Panichella, Sebastiano and Leuenberger, Manuel and Di Sorbo, Andrea and Nierstrasz, Oscar},\n",
        "                journal={Journal of systems and software},\n",
        "                volume={181},\n",
        "                pages={111047},\n",
        "                year={2021},\n",
        "                publisher={Elsevier}\n",
        "              }\n",
        "@INPROCEEDINGS{AlKaswan2023,\n",
        "                author={Al-Kaswan, Ali and Izadi, Maliheh and Van Deursen, Arie},\n",
        "                booktitle={2023 IEEE/ACM 2nd International Workshop on Natural Language-Based Software Engineering (NLBSE)},\n",
        "                title={STACC: Code Comment Classification using SentenceTransformers},\n",
        "                year={2023},\n",
        "                pages={28-31}\n",
        "              }\n",
        "@inproceedings{pascarella2017,\n",
        "                title={Classifying code comments in Java open-source software systems},\n",
        "                author={Pascarella, Luca and Bacchelli, Alberto},\n",
        "                booktitle={2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)},\n",
        "                year={2017},\n",
        "                organization={IEEE}\n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uVkNVJdwRDbx",
        "outputId": "61993c57-d380-4260-eef0-ba60412153b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setfit in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: datasets>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (3.1.0)\n",
            "Requirement already satisfied: sentence-transformers>=3 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers[train]>=3->setfit) (3.2.1)\n",
            "Requirement already satisfied: transformers>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (4.42.2)\n",
            "Requirement already satisfied: evaluate>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (0.26.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from setfit) (1.5.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from setfit) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.15.0->setfit) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (3.11.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->setfit) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->setfit) (4.12.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (11.0.0)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers[train]>=3->setfit) (1.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.0->setfit) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.0->setfit) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.41.0->setfit) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->sentence-transformers[train]>=3->setfit) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.15.0->setfit) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.15.0->setfit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.15.0->setfit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.15.0->setfit) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.15.0->setfit) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers==4.42.2 in /usr/local/lib/python3.10/dist-packages (4.42.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (0.26.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.42.2) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.2) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.42.2) (2024.8.30)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade setfit\n",
        "!pip install --upgrade huggingface_hub\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip3 install transformers==4.42.2\n",
        "!pip3 install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxa9zFlme9_s"
      },
      "source": [
        "**Important note:** We made sure to include the imports and original dataset from the baseline just in case we missed anything. This was the only thing that we pulled from the baseline code. The rest is from our own research."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8mtdr4mRDb0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from setfit import SetFitModel, SetFitTrainer, Trainer\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9RyzqU92Y5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7a7ed529-9dcc-40c1-b605-5d8cc09afc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ypPEVqqVReOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb9ae0e-0600-450f-f7e5-f3fa0ae295c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    java_train: Dataset({\n",
              "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
              "        num_rows: 7614\n",
              "    })\n",
              "    java_test: Dataset({\n",
              "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
              "        num_rows: 1725\n",
              "    })\n",
              "    python_train: Dataset({\n",
              "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
              "        num_rows: 1884\n",
              "    })\n",
              "    python_test: Dataset({\n",
              "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
              "        num_rows: 406\n",
              "    })\n",
              "    pharo_train: Dataset({\n",
              "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
              "        num_rows: 1298\n",
              "    })\n",
              "    pharo_test: Dataset({\n",
              "        features: ['index', 'class', 'comment_sentence', 'partition', 'combo', 'labels'],\n",
              "        num_rows: 289\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "langs = ['java', 'python', 'pharo']\n",
        "labels = {\n",
        "    'java': ['summary', 'Ownership', 'Expand', 'usage', 'Pointer', 'deprecation', 'rational'],\n",
        "    'python': ['Usage', 'Parameters', 'DevelopmentNotes', 'Expand', 'Summary'],\n",
        "    'pharo': ['Keyimplementationpoints', 'Example', 'Responsibilities', 'Classreferences', 'Intent', 'Keymessages', 'Collaborators']\n",
        "}\n",
        "ds = load_dataset('NLBSE/nlbse25-code-comment-classification')\n",
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4FaiaaFfc5V"
      },
      "source": [
        "Since our dataset consists of multiple sets for different languages and different labels for each, we split up our project into three parts in order to classify each since we did not have an idea as to how to combine this into one model. Our first order of business was to get an idea of what models would be best suited for this application, so we did testing on the Java dataset first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94Ih493VgROq"
      },
      "source": [
        "# Part 1: Testing Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIYC3HEUY_h1"
      },
      "source": [
        "### Loading Data\n",
        "\n",
        "In order to load in our data, we accessed the dataset that we loaded in previously, and focused on extracting only the java train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gMfTdNncRh5i"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Loading Java for processing\n",
        "#\n",
        "\n",
        "java_labels = labels['java']  # These Labels represented as words\n",
        "\n",
        "java_train = ds['java_train'].to_pandas()\n",
        "java_train_labels = ds['java_train']['labels']  #These labels represented as [1,0,0,0,0], One-Hot Encoding\n",
        "\n",
        "#java_train_true_labels = [java_labels[i] for i in np.argmax(java_train_labels, axis=1)]\n",
        "\n",
        "\n",
        "\n",
        "java_test = ds['java_test'].to_pandas()\n",
        "java_test_labels = ds['java_test']['labels']\n",
        "\n",
        "#java_test_true_labels = [java_labels[i] for i in np.argmax(java_test_labels, axis=1)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Ot7-sXZA9y"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "In order to handle our data preprocessing, we mainly focused on using CountVectorization, which we discovered through our research. Using this model, we create a 'bag of words' which we can modify by changing different parameters in our Count Vectorization. Some of the preprocessing methods that we wanted to focus on was removing stop words, making all words lowercase, and changing the n-gram range. Below are some of the links that we used in order to accomplish this goal.\n",
        "\n",
        "\n",
        "- [Count Vectorization](https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "\n",
        "- [Bag of Words](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
        "\n",
        "- [Text Preprocessing](https://www.geeksforgeeks.org/text-preprocessing-in-python-set-1/)\n",
        "\n",
        "- [Text Preprocessing using Count Vectorizers](https://towardsdatascience.com/basics-of-countvectorizer-e26677900f9c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM4XJ1jVZOli"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "#\n",
        "# For preprocessing, we are using CountVectorizer in order to handle our preprocessing since it makes it easy\n",
        "#\n",
        "\n",
        "stop_words = [ 'todo', 'is','a', 'for', 'it', 'its','of','and','to' ]\n",
        "def preprocess_text(train, test):\n",
        "\n",
        "  vectorizer = TfidfVectorizer(lowercase = True, stop_words=stop_words, ngram_range=(1,1))\n",
        "  train_vectorized = vectorizer.fit_transform(train)\n",
        "  test_vectorized = vectorizer.transform(test)\n",
        "\n",
        "  return train_vectorized, test_vectorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkGH-ykCZoRj"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# We only need the comments. The rest of the comments we think are invalid\n",
        "# Since the comments are encoded, we use this so we can determine an integer value to represent the label\n",
        "#\n",
        "java_train_combo = ds['java_train']['combo']\n",
        "java_train_labels_int = np.argmax(java_train_labels, axis=1)\n",
        "\n",
        "java_test_combo= ds['java_test']['combo']\n",
        "java_test_labels_int = np.argmax(java_test_labels, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0R0MIHlgGje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16797d1-e0c5-452a-dd43-fd1aaf5a49bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Java train:\n",
            "Data shape:  (7614, 7081)\n",
            "Labels shape:  (7614,)\n",
            "\n",
            "Java test:\n",
            "Data shape:  (1725, 7081)\n",
            "Labels shape:  (1725,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "java_train_vectorized, java_test_vectorized = preprocess_text(java_train_combo, java_test_combo)\n",
        "\n",
        "\n",
        "print(\"Java train:\")\n",
        "print(\"Data shape: \",java_train_vectorized.shape)\n",
        "print(\"Labels shape: \",java_train_labels_int.shape)\n",
        "print()\n",
        "print(\"Java test:\")\n",
        "print(\"Data shape: \",java_test_vectorized.shape)\n",
        "print(\"Labels shape: \",java_test_labels_int.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1A: Logistic Regression"
      ],
      "metadata": {
        "id": "5dRxlU8Eg8Lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our first attempt at creating our model was using logistic regression. We found this method through our research, and also through our lecture slides as well. This was going to serve as our first attempt in order to see where we were out. It was our sort of \"baseline\" since it was simple to setup.\n",
        "\n",
        "Logistic Regression works well for multi-class problems and since we are working with words with vectors that will be sparse, it was a good first chocie."
      ],
      "metadata": {
        "id": "14m9Pohx09zr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTE0kez-cHWL"
      },
      "source": [
        "\n",
        "\n",
        "- [Word Classification](https://medium.com/analytics-vidhya/nlp-tutorial-for-text-classification-in-python-8f19cd17b49e)\n",
        "\n",
        "- [Logistic Regression](https://spotintelligence.com/2023/02/22/logistic-regression-text-classification-python/#:~:text=Once%20the%20model%20is%20trained,complex%20models%20in%20ensemble%20approaches.)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "WozvBAtDgwJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgJrWAyDcJT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6366d2-01da-480f-8023-0ab7b4b0e46b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.7773399014778325, 'recall': 0.8845291479820628, 'f1-score': 0.8274777136864184, 'support': 892.0}, '1': {'precision': 1.0, 'recall': 0.9555555555555556, 'f1-score': 0.9772727272727273, 'support': 45.0}, '2': {'precision': 0.7058823529411765, 'recall': 0.12, 'f1-score': 0.20512820512820512, 'support': 100.0}, '3': {'precision': 0.8091603053435115, 'recall': 0.7447306791569087, 'f1-score': 0.775609756097561, 'support': 427.0}, '4': {'precision': 0.6949152542372882, 'recall': 0.9213483146067416, 'f1-score': 0.7922705314009661, 'support': 178.0}, '5': {'precision': 1.0, 'recall': 0.4, 'f1-score': 0.5714285714285714, 'support': 15.0}, '6': {'precision': 0.4666666666666667, 'recall': 0.10294117647058823, 'f1-score': 0.1686746987951807, 'support': 68.0}, 'accuracy': 0.776231884057971, 'macro avg': {'precision': 0.7791377829523537, 'recall': 0.589872124824551, 'f1-score': 0.6168374576870901, 'support': 1725.0}, 'weighted avg': {'precision': 0.768066739931359, 'recall': 0.776231884057971, 'f1-score': 0.7506382854382085, 'support': 1725.0}}\n"
          ]
        }
      ],
      "source": [
        "java_model = LogisticRegression(max_iter=1000)\n",
        "java_model.fit(java_train_vectorized, java_train_labels_int)\n",
        "\n",
        "predictions = java_model.predict(java_test_vectorized)\n",
        "java_original_results = classification_report(java_test_labels_int, predictions, output_dict=True)\n",
        "\n",
        "print(java_original_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on our results, our data is comparable to what the baseline uses, which was SetFit models. With what we learned, we then attempted to improve on this model by using pipelines, other vectorizers and models."
      ],
      "metadata": {
        "id": "Q1NNUf4UVIF8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_CJJG4MCwuo"
      },
      "source": [
        "## 1B: Pipeline models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HYrz1zBMq50"
      },
      "source": [
        "Here is where we researched the effectiveness of other possble models, it allows us to look at the accuracy across all the labels in order to determine which vectorizer and model resulted in the best accuracy with minimal configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created two sets of models in order to test these classifiers. Many of these classifers were classifiers we learned about in CS345. One set uses CountVectorizer and another set uses TFIDFVectorizers."
      ],
      "metadata": {
        "id": "89oykJ1h1R7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_pipeline_creator(classifier):\n",
        "    pipeline = Pipeline([\n",
        "      ('countvectorizer', CountVectorizer(lowercase = True) ),\n",
        "      ('clf', classifier)\n",
        "    ])\n",
        "    return pipeline\n",
        "\n",
        "def tfidf_pipeline_creator(classifier):\n",
        "    pipeline = Pipeline([\n",
        "      ('tfidf', TfidfVectorizer() ),\n",
        "      ('clf', classifier)\n",
        "    ])\n",
        "    return pipeline\n",
        "\n",
        "def use_pipeline(pipeline, train_data, train_labels, test_data, test_labels):\n",
        "  pipeline.fit(train_data, train_labels)\n",
        "  predictions = pipeline.predict(test_data)\n",
        "  return classification_report(test_labels, predictions, output_dict=True)"
      ],
      "metadata": {
        "id": "cvnTZJuALhNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9af6ad-bbd4-4ad3-c137-bf6c3721076a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CountVectorizer Pipelines:\n",
        "Our first set of pipelines uses classifiers with our CoutVectorizer. Some of the classifiers we tried to use included Multinomial and Complement Naive Bayes, Linear SVCs and RandomForest classifiers. Many of thes classifiers like the MultinomialNB work well for word classification and we also decieded to include other classifiers we were familiar with as a comparison."
      ],
      "metadata": {
        "id": "7vhc5fA8993b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CountVectorizer pipelines\n",
        "pipelineMNB_count = count_pipeline_creator(MultinomialNB())\n",
        "pipelineCNB_count = count_pipeline_creator(ComplementNB())\n",
        "pipelineLR_count = count_pipeline_creator(LogisticRegression())\n",
        "pipelineSVC_count = count_pipeline_creator(LinearSVC())\n",
        "pipelineRF_count = count_pipeline_creator(RandomForestClassifier(n_estimators=100, random_state=42))"
      ],
      "metadata": {
        "id": "MEQiALhvRIi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count Vectorizer Training & Testing:"
      ],
      "metadata": {
        "id": "bHpijr8y1-aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"COUNT VECTORIZER\")\n",
        "\n",
        "print(\"Pipeline 1:\")\n",
        "print(use_pipeline(pipelineMNB_count, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 2:\")\n",
        "print(use_pipeline(pipelineCNB_count, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 3:\")\n",
        "print(use_pipeline(pipelineLR_count, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 4:\")\n",
        "print(use_pipeline(pipelineSVC_count, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 5:\")\n",
        "print(use_pipeline(pipelineRF_count, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))"
      ],
      "metadata": {
        "id": "iM0Nva9Z134d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f7d592-e43e-4ad4-f07f-589b9fb42d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COUNT VECTORIZER\n",
            "Pipeline 1:\n",
            "{'0': {'precision': 0.7353535353535353, 'recall': 0.8161434977578476, 'f1-score': 0.7736450584484591, 'support': 892.0}, '1': {'precision': 0.9772727272727273, 'recall': 0.9555555555555556, 'f1-score': 0.9662921348314607, 'support': 45.0}, '2': {'precision': 0.30434782608695654, 'recall': 0.14, 'f1-score': 0.1917808219178082, 'support': 100.0}, '3': {'precision': 0.6933962264150944, 'recall': 0.6885245901639344, 'f1-score': 0.690951821386604, 'support': 427.0}, '4': {'precision': 0.7474226804123711, 'recall': 0.8146067415730337, 'f1-score': 0.7795698924731183, 'support': 178.0}, '5': {'precision': 1.0, 'recall': 0.13333333333333333, 'f1-score': 0.23529411764705882, 'support': 15.0}, '6': {'precision': 0.2, 'recall': 0.07352941176470588, 'f1-score': 0.10752688172043011, 'support': 68.0}, 'accuracy': 0.7136231884057971, 'macro avg': {'precision': 0.665398999362955, 'recall': 0.5173847328783443, 'f1-score': 0.5350086754892771, 'support': 1725.0}, 'weighted avg': {'precision': 0.6887355563269387, 'recall': 0.7136231884057971, 'f1-score': 0.6941412920053404, 'support': 1725.0}}\n",
            "Pipeline 2:\n",
            "{'0': {'precision': 0.7877984084880637, 'recall': 0.6659192825112108, 'f1-score': 0.7217496962332929, 'support': 892.0}, '1': {'precision': 0.75, 'recall': 1.0, 'f1-score': 0.8571428571428571, 'support': 45.0}, '2': {'precision': 0.22764227642276422, 'recall': 0.28, 'f1-score': 0.25112107623318386, 'support': 100.0}, '3': {'precision': 0.7166666666666667, 'recall': 0.7049180327868853, 'f1-score': 0.7107438016528925, 'support': 427.0}, '4': {'precision': 0.6060606060606061, 'recall': 0.898876404494382, 'f1-score': 0.7239819004524887, 'support': 178.0}, '5': {'precision': 0.5833333333333334, 'recall': 0.4666666666666667, 'f1-score': 0.5185185185185185, 'support': 15.0}, '6': {'precision': 0.14130434782608695, 'recall': 0.19117647058823528, 'f1-score': 0.1625, 'support': 68.0}, 'accuracy': 0.6655072463768116, 'macro avg': {'precision': 0.5446865198282173, 'recall': 0.6010795510067686, 'f1-score': 0.563679692890462, 'support': 1725.0}, 'weighted avg': {'precision': 0.6907156859195699, 'recall': 0.6655072463768116, 'f1-score': 0.6716918403472175, 'support': 1725.0}}\n",
            "Pipeline 3:\n",
            "{'0': {'precision': 0.8131749460043196, 'recall': 0.844170403587444, 'f1-score': 0.8283828382838284, 'support': 892.0}, '1': {'precision': 0.9777777777777777, 'recall': 0.9777777777777777, 'f1-score': 0.9777777777777777, 'support': 45.0}, '2': {'precision': 0.42857142857142855, 'recall': 0.24, 'f1-score': 0.3076923076923077, 'support': 100.0}, '3': {'precision': 0.8165829145728644, 'recall': 0.7611241217798594, 'f1-score': 0.7878787878787878, 'support': 427.0}, '4': {'precision': 0.7304347826086957, 'recall': 0.9438202247191011, 'f1-score': 0.8235294117647058, 'support': 178.0}, '5': {'precision': 0.8571428571428571, 'recall': 0.4, 'f1-score': 0.5454545454545454, 'support': 15.0}, '6': {'precision': 0.20634920634920634, 'recall': 0.19117647058823528, 'f1-score': 0.1984732824427481, 'support': 68.0}, 'accuracy': 0.7727536231884058, 'macro avg': {'precision': 0.6900048447181641, 'recall': 0.6225812854932026, 'f1-score': 0.6384555644706715, 'support': 1725.0}, 'weighted avg': {'precision': 0.7639399300920845, 'recall': 0.7727536231884058, 'f1-score': 0.7642766386230091, 'support': 1725.0}}\n",
            "Pipeline 4:\n",
            "{'0': {'precision': 0.8117942283563363, 'recall': 0.7253363228699552, 'f1-score': 0.7661338069863824, 'support': 892.0}, '1': {'precision': 0.9565217391304348, 'recall': 0.9777777777777777, 'f1-score': 0.967032967032967, 'support': 45.0}, '2': {'precision': 0.26605504587155965, 'recall': 0.29, 'f1-score': 0.27751196172248804, 'support': 100.0}, '3': {'precision': 0.7476415094339622, 'recall': 0.7423887587822015, 'f1-score': 0.745005875440658, 'support': 427.0}, '4': {'precision': 0.7124463519313304, 'recall': 0.9325842696629213, 'f1-score': 0.8077858880778589, 'support': 178.0}, '5': {'precision': 0.46153846153846156, 'recall': 0.4, 'f1-score': 0.42857142857142855, 'support': 15.0}, '6': {'precision': 0.13592233009708737, 'recall': 0.20588235294117646, 'f1-score': 0.16374269005847952, 'support': 68.0}, 'accuracy': 0.7089855072463768, 'macro avg': {'precision': 0.5845599523370246, 'recall': 0.6105670688620046, 'f1-score': 0.593683516841466, 'support': 1725.0}, 'weighted avg': {'precision': 0.7281122348310929, 'recall': 0.7089855072463768, 'f1-score': 0.7154350763850164, 'support': 1725.0}}\n",
            "Pipeline 5:\n",
            "{'0': {'precision': 0.7730294396961064, 'recall': 0.9125560538116592, 'f1-score': 0.8370179948586118, 'support': 892.0}, '1': {'precision': 0.9782608695652174, 'recall': 1.0, 'f1-score': 0.989010989010989, 'support': 45.0}, '2': {'precision': 0.5555555555555556, 'recall': 0.05, 'f1-score': 0.09174311926605505, 'support': 100.0}, '3': {'precision': 0.8337801608579088, 'recall': 0.7283372365339579, 'f1-score': 0.7775, 'support': 427.0}, '4': {'precision': 0.748898678414097, 'recall': 0.9550561797752809, 'f1-score': 0.8395061728395061, 'support': 178.0}, '5': {'precision': 0.8571428571428571, 'recall': 0.4, 'f1-score': 0.5454545454545454, 'support': 15.0}, '6': {'precision': 0.5, 'recall': 0.07352941176470588, 'f1-score': 0.1282051282051282, 'support': 68.0}, 'accuracy': 0.7860869565217391, 'macro avg': {'precision': 0.7495239373188204, 'recall': 0.5884969831265148, 'f1-score': 0.601205421376405, 'support': 1725.0}, 'weighted avg': {'precision': 0.7682926325774472, 'recall': 0.7860869565217391, 'f1-score': 0.7528256368180759, 'support': 1725.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tfidf Vectorizer Pipelines:\n",
        "Our Tfidf Vectorizer was our next approach. This vectorizes in a similar approach to the CountVectoriers, but it takes in weights and adjusts for words that occur more and carry weight."
      ],
      "metadata": {
        "id": "Q2CEwJL41t0r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL6Bhm5c6AuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a84d9ef-38c9-44e0-dc11-e7da4c6e6153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "#TfidfVectorizer pipelines\n",
        "pipelineMNB_tfidf = tfidf_pipeline_creator(MultinomialNB())\n",
        "pipelineCNB_tfidf = tfidf_pipeline_creator(ComplementNB())\n",
        "pipelineLR_tfidf = tfidf_pipeline_creator(LogisticRegression())\n",
        "pipelineSVC_tfidf = tfidf_pipeline_creator(LinearSVC())\n",
        "pipelineRF_tfidf = tfidf_pipeline_creator(RandomForestClassifier(n_estimators=100, random_state=42))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tfidf Vectorizer Training & Testing:"
      ],
      "metadata": {
        "id": "5alte0oR93cj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2sCsUaGP5__D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef644041-d844-4a69-a2b9-5af0abf9698a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF\n",
            "Pipeline 6:\n",
            "{'0': {'precision': 0.614529280948851, 'recall': 0.929372197309417, 'f1-score': 0.7398482820169567, 'support': 892.0}, '1': {'precision': 1.0, 'recall': 0.7333333333333333, 'f1-score': 0.8461538461538461, 'support': 45.0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100.0}, '3': {'precision': 0.7300380228136882, 'recall': 0.4496487119437939, 'f1-score': 0.5565217391304348, 'support': 427.0}, '4': {'precision': 0.65, 'recall': 0.29213483146067415, 'f1-score': 0.40310077519379844, 'support': 178.0}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 68.0}, 'accuracy': 0.6411594202898551, 'macro avg': {'precision': 0.42779532910893414, 'recall': 0.3434984391496026, 'f1-score': 0.36366066321357654, 'support': 1725.0}, 'weighted avg': {'precision': 0.5916442633900405, 'recall': 0.6411594202898551, 'f1-score': 0.5840048181039075, 'support': 1725.0}}\n",
            "Pipeline 7:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.7423167848699763, 'recall': 0.7040358744394619, 'f1-score': 0.7226697353279632, 'support': 892.0}, '1': {'precision': 0.7894736842105263, 'recall': 1.0, 'f1-score': 0.8823529411764706, 'support': 45.0}, '2': {'precision': 0.2111111111111111, 'recall': 0.19, 'f1-score': 0.2, 'support': 100.0}, '3': {'precision': 0.6896551724137931, 'recall': 0.6088992974238876, 'f1-score': 0.6467661691542289, 'support': 427.0}, '4': {'precision': 0.625, 'recall': 0.898876404494382, 'f1-score': 0.7373271889400922, 'support': 178.0}, '5': {'precision': 0.4117647058823529, 'recall': 0.4666666666666667, 'f1-score': 0.4375, 'support': 15.0}, '6': {'precision': 0.13414634146341464, 'recall': 0.16176470588235295, 'f1-score': 0.14666666666666667, 'support': 68.0}, 'accuracy': 0.6550724637681159, 'macro avg': {'precision': 0.5147811142787392, 'recall': 0.5757489927009644, 'f1-score': 0.5390403858950602, 'support': 1725.0}, 'weighted avg': {'precision': 0.6607624228597339, 'recall': 0.6550724637681159, 'f1-score': 0.654073341135658, 'support': 1725.0}}\n",
            "Pipeline 8:\n",
            "{'0': {'precision': 0.7801766437684003, 'recall': 0.8912556053811659, 'f1-score': 0.8320251177394035, 'support': 892.0}, '1': {'precision': 1.0, 'recall': 0.9555555555555556, 'f1-score': 0.9772727272727273, 'support': 45.0}, '2': {'precision': 0.6470588235294118, 'recall': 0.11, 'f1-score': 0.18803418803418803, 'support': 100.0}, '3': {'precision': 0.8075949367088607, 'recall': 0.747072599531616, 'f1-score': 0.7761557177615572, 'support': 427.0}, '4': {'precision': 0.7161572052401747, 'recall': 0.9213483146067416, 'f1-score': 0.8058968058968059, 'support': 178.0}, '5': {'precision': 1.0, 'recall': 0.4, 'f1-score': 0.5714285714285714, 'support': 15.0}, '6': {'precision': 0.4375, 'recall': 0.10294117647058823, 'f1-score': 0.16666666666666666, 'support': 68.0}, 'accuracy': 0.7797101449275362, 'macro avg': {'precision': 0.769783944178121, 'recall': 0.5897390359350954, 'f1-score': 0.6167828278285601, 'support': 1725.0}, 'weighted avg': {'precision': 0.7667782429575588, 'recall': 0.7797101449275362, 'f1-score': 0.753460858778445, 'support': 1725.0}}\n",
            "Pipeline 9:\n",
            "{'0': {'precision': 0.8137142857142857, 'recall': 0.7982062780269058, 'f1-score': 0.8058856819468024, 'support': 892.0}, '1': {'precision': 0.9183673469387755, 'recall': 1.0, 'f1-score': 0.9574468085106383, 'support': 45.0}, '2': {'precision': 0.36764705882352944, 'recall': 0.25, 'f1-score': 0.2976190476190476, 'support': 100.0}, '3': {'precision': 0.7874396135265701, 'recall': 0.7634660421545667, 'f1-score': 0.7752675386444708, 'support': 427.0}, '4': {'precision': 0.7155172413793104, 'recall': 0.9325842696629213, 'f1-score': 0.8097560975609757, 'support': 178.0}, '5': {'precision': 0.5454545454545454, 'recall': 0.4, 'f1-score': 0.46153846153846156, 'support': 15.0}, '6': {'precision': 0.14473684210526316, 'recall': 0.16176470588235295, 'f1-score': 0.1527777777777778, 'support': 68.0}, 'accuracy': 0.7484057971014493, 'macro avg': {'precision': 0.6132681334203255, 'recall': 0.6151458993895353, 'f1-score': 0.6086130590854534, 'support': 1725.0}, 'weighted avg': {'precision': 0.745244687964104, 'recall': 0.7484057971014493, 'f1-score': 0.7444549736930087, 'support': 1725.0}}\n",
            "Pipeline 10:\n",
            "{'0': {'precision': 0.7568331762488218, 'recall': 0.9002242152466368, 'f1-score': 0.8223246287762417, 'support': 892.0}, '1': {'precision': 0.9777777777777777, 'recall': 0.9777777777777777, 'f1-score': 0.9777777777777777, 'support': 45.0}, '2': {'precision': 0.2857142857142857, 'recall': 0.02, 'f1-score': 0.037383177570093455, 'support': 100.0}, '3': {'precision': 0.825136612021858, 'recall': 0.7072599531615925, 'f1-score': 0.7616645649432535, 'support': 427.0}, '4': {'precision': 0.7681818181818182, 'recall': 0.949438202247191, 'f1-score': 0.8492462311557789, 'support': 178.0}, '5': {'precision': 0.6, 'recall': 0.4, 'f1-score': 0.48, 'support': 15.0}, '6': {'precision': 0.3125, 'recall': 0.07352941176470588, 'f1-score': 0.11904761904761904, 'support': 68.0}, 'accuracy': 0.7715942028985507, 'macro avg': {'precision': 0.6465919528492231, 'recall': 0.5754613657425577, 'f1-score': 0.5782062856101092, 'support': 1725.0}, 'weighted avg': {'precision': 0.73448482246671, 'recall': 0.7715942028985507, 'f1-score': 0.737938390201248, 'support': 1725.0}}\n"
          ]
        }
      ],
      "source": [
        "print(\"TFIDF\")\n",
        "\n",
        "print(\"Pipeline 6:\")\n",
        "print(use_pipeline(pipelineMNB_tfidf, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 7:\")\n",
        "print(use_pipeline(pipelineCNB_tfidf, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 8:\")\n",
        "print(use_pipeline(pipelineLR_tfidf, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 9:\")\n",
        "print(use_pipeline(pipelineSVC_tfidf, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 10:\")\n",
        "print(use_pipeline(pipelineRF_tfidf, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G0uxMm7_SdU"
      },
      "source": [
        "From the above outputs we can see that the highest average accuracy provided was from the 8th element TFIDF Vectorizer with the Logistic Regression Model, it had the highest average f1 score across all the categories so we will use it as our baseline and fine tune it to achieve the best accuracy.\n",
        "\n",
        "One important note that we discovered was each dataset performed slightly better depending on certain pipelines we created. In order to mitigate this, each section we tested the different pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we used GridSearch, a method we learned from CS345 which tests a model using different parameters, and gives us the best parameters along with the best accuracies as well. Additionally, we ran the pipeline once again to see what the accuracies were at."
      ],
      "metadata": {
        "id": "e-uEbAg83xBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Pipeline:"
      ],
      "metadata": {
        "id": "9IYb45imhl6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pipeline 5:\")\n",
        "java_pipeline_results = use_pipeline(pipelineRF_count, java_train_combo, java_train_labels_int, java_test_combo, java_test_labels_int)\n",
        "print(java_pipeline_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVJ94UhwhnNy",
        "outputId": "70649bcd-c6c1-4248-b286-79df4ff630d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline 5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.7730294396961064, 'recall': 0.9125560538116592, 'f1-score': 0.8370179948586118, 'support': 892.0}, '1': {'precision': 0.9782608695652174, 'recall': 1.0, 'f1-score': 0.989010989010989, 'support': 45.0}, '2': {'precision': 0.5555555555555556, 'recall': 0.05, 'f1-score': 0.09174311926605505, 'support': 100.0}, '3': {'precision': 0.8337801608579088, 'recall': 0.7283372365339579, 'f1-score': 0.7775, 'support': 427.0}, '4': {'precision': 0.748898678414097, 'recall': 0.9550561797752809, 'f1-score': 0.8395061728395061, 'support': 178.0}, '5': {'precision': 0.8571428571428571, 'recall': 0.4, 'f1-score': 0.5454545454545454, 'support': 15.0}, '6': {'precision': 0.5, 'recall': 0.07352941176470588, 'f1-score': 0.1282051282051282, 'support': 68.0}, 'accuracy': 0.7860869565217391, 'macro avg': {'precision': 0.7495239373188204, 'recall': 0.5884969831265148, 'f1-score': 0.601205421376405, 'support': 1725.0}, 'weighted avg': {'precision': 0.7682926325774472, 'recall': 0.7860869565217391, 'f1-score': 0.7528256368180759, 'support': 1725.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search Optimization:"
      ],
      "metadata": {
        "id": "mDwne0lplBqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RkVzJhR-zOhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "954c8f7f-f68a-424d-877f-0a5682eccd00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'clf__n_estimators': 150, 'countvectorizer__ngram_range': (1, 1)}\n",
            "Best score: 0.7784472516464582\n",
            "{'0': {'precision': 0.771050141911069, 'recall': 0.9136771300448431, 'f1-score': 0.836326321190354, 'support': 892.0}, '1': {'precision': 0.9782608695652174, 'recall': 1.0, 'f1-score': 0.989010989010989, 'support': 45.0}, '2': {'precision': 0.45454545454545453, 'recall': 0.05, 'f1-score': 0.09009009009009009, 'support': 100.0}, '3': {'precision': 0.8387978142076503, 'recall': 0.7189695550351288, 'f1-score': 0.7742749054224464, 'support': 427.0}, '4': {'precision': 0.748898678414097, 'recall': 0.9550561797752809, 'f1-score': 0.8395061728395061, 'support': 178.0}, '5': {'precision': 0.8571428571428571, 'recall': 0.4, 'f1-score': 0.5454545454545454, 'support': 15.0}, '6': {'precision': 0.45454545454545453, 'recall': 0.07352941176470588, 'f1-score': 0.12658227848101267, 'support': 68.0}, 'accuracy': 0.7843478260869565, 'macro avg': {'precision': 0.729034467190257, 'recall': 0.587318896659994, 'f1-score': 0.6001779003555633, 'support': 1725.0}, 'weighted avg': {'precision': 0.7608636964407326, 'recall': 0.7843478260869565, 'f1-score': 0.7515098426177642, 'support': 1725.0}}\n"
          ]
        }
      ],
      "source": [
        "parameters = {\n",
        "    'countvectorizer__ngram_range':((1,1),(1,2)),\n",
        "    'clf__n_estimators': (50, 150, 500),\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipelineRF_count, parameters, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(java_train_combo, java_train_labels_int)\n",
        "\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best score:\", grid_search.best_score_)\n",
        "\n",
        "java_tuned_results = classification_report(java_test_labels_int, grid_search.best_estimator_.predict(java_test_combo), output_dict=True)\n",
        "print(java_tuned_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, this pipeline along with some optimization was able to perform slightly better than our Logistic Regression. Interestingly enough, when we repeated this process with other datasets, we discovered that they were subject to overfitting (more on that later)."
      ],
      "metadata": {
        "id": "wqxYgyZ3Wqko"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajoui70-C40N"
      },
      "source": [
        "## 1C: Setfit model optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also opted to test the SetFit model using a pretrained model just like the baseline. The NLBSE uses its own pretrained model, so we opted to look for a similar one to test since Transformers perform better in this area. We looked through the [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) in order to find a model suitable for our application but opted to use a base model of BERT \"bert-base-uncased\".\n",
        "\n",
        "Below, we created a small subset from our data for testing purposes. Since we can't use our entire dataset due to time constraints, we tested as such."
      ],
      "metadata": {
        "id": "DbehRWKl38tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = ds['java_train'].shuffle(seed=39)\n",
        "train = train.select(range(30))\n",
        "\n",
        "print(np.sum(train['labels'], axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHv0LzQXYarO",
        "outputId": "35cbf88d-ab90-49aa-b520-d88041e38b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13  1  2 10  3  1  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lWyegtxFCLy"
      },
      "outputs": [],
      "source": [
        "# This code is based on the baseline code, it has been adapted to use a different pretrained model with a subset of the data for faster processing time\n",
        "\n",
        "# sfm = SetFitModel.from_pretrained(\"bert-base-uncased\", multi_target_strategy=\"multi-output\")\n",
        "\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     train_dataset=ds['java_train'],\n",
        "#     eval_dataset=ds['java_test'],\n",
        "#     column_mapping={\"combo\": \"text\", \"labels\": \"label\"},\n",
        "#     model=sfm,\n",
        "# )\n",
        "\n",
        "# trainer.train()\n",
        "# metrics = trainer.evaluate()\n",
        "# print(metrics)\n",
        "\n",
        "# predictions = sfm.predict(ds['java_test']['combo'])\n",
        "# print(classification_report(ds['pjava_test']['labels'], predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the primary problems with setfit is the amount of time and processing power it requires in order to get good results. Running in an environment with an i9 intell CPU still took ~33 minutes on just 100 rows of data. Resulting in around 70% accuracy. Running this on the 7614 rows of java_train data would take a very long time. This could be completed utilizing better hardware notably a GPU with adequet memory.\n",
        "For this project it is out of the scope of what we could attempt."
      ],
      "metadata": {
        "id": "4u8Skg6rbufl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdIyyMVrgUzx"
      },
      "source": [
        "# Part 2: Other Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With these testing methods in mind, we set out to test our models on the Python and Pharo datasets. We repeated the same process above, so this was our results from our testing."
      ],
      "metadata": {
        "id": "sBLb3eHTXOIP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywhXF0iQZGhj"
      },
      "source": [
        "## 2A: Python Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmSHeJUfZMZp"
      },
      "outputs": [],
      "source": [
        "# Loading Python for processing\n",
        "#\n",
        "\n",
        "python_labels = labels['python']  # These Labels represented as words\n",
        "\n",
        "python_train = ds['python_train'].to_pandas()\n",
        "python_train_labels = ds['python_train']['labels']  # These labels represented as [1, 0, 0, 0, 0], One-Hot Encoding\n",
        "\n",
        "python_test = ds['python_test'].to_pandas()\n",
        "python_test_labels = ds['python_test']['labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80N1auscZMk7"
      },
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOHYqbvO1oSB"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stop_words = ['the', 'todo', 'is','a', 'this', 'for', 'it', 'its' ]\n",
        "\n",
        "def preprocess_text(train, test):\n",
        "\n",
        "  vectorizer = CountVectorizer(lowercase = True, stop_words=stop_words)\n",
        "  train_vectorized = vectorizer.fit_transform(train)\n",
        "  test_vectorized = vectorizer.transform(test)\n",
        "\n",
        "  return train_vectorized, test_vectorized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7IvIdYV8TjG"
      },
      "outputs": [],
      "source": [
        "python_train_combo = ds['python_train']['combo']\n",
        "python_train_labels_int = np.argmax(python_train_labels, axis=1)\n",
        "\n",
        "python_test_combo = ds['python_test']['combo']\n",
        "python_test_labels_int = np.argmax(python_test_labels, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljp064zX-1eE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692243e9-9168-403c-9faf-da9a05b9da00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python train:\n",
            "Data shape:  (1884, 2550)\n",
            "Labels shape:  (1884,)\n",
            "\n",
            "Python test:\n",
            "Data shape:  (406, 2550)\n",
            "Labels shape:  (406,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "python_train_vectorized, python_test_vectorized = preprocess_text(python_train_combo, python_test_combo)\n",
        "\n",
        "print(\"Python train:\")\n",
        "print(\"Data shape: \",python_train_vectorized.shape)\n",
        "print(\"Labels shape: \",python_train_labels_int.shape)\n",
        "print()\n",
        "print(\"Python test:\")\n",
        "print(\"Data shape: \",python_test_vectorized.shape)\n",
        "print(\"Labels shape: \",python_test_labels_int.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "YO5oUIVUk3Ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjz61xEk_Myy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b00ced0-b45e-4d80-9b27-46c4b3668e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.589041095890411, 'recall': 0.7107438016528925, 'f1-score': 0.6441947565543071, 'support': 121.0}, '1': {'precision': 0.7777777777777778, 'recall': 0.7716535433070866, 'f1-score': 0.7747035573122529, 'support': 127.0}, '2': {'precision': 0.09523809523809523, 'recall': 0.06060606060606061, 'f1-score': 0.07407407407407407, 'support': 33.0}, '3': {'precision': 0.4375, 'recall': 0.2916666666666667, 'f1-score': 0.35, 'support': 48.0}, '4': {'precision': 0.48148148148148145, 'recall': 0.5064935064935064, 'f1-score': 0.4936708860759494, 'support': 77.0}, 'accuracy': 0.5886699507389163, 'macro avg': {'precision': 0.4762076900775531, 'recall': 0.4682327157452425, 'f1-score': 0.46732865480331676, 'support': 406.0}, 'weighted avg': {'precision': 0.5696272945749968, 'recall': 0.5886699507389163, 'f1-score': 0.5753498029409356, 'support': 406.0}}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "python_model = LogisticRegression(max_iter=1000)\n",
        "python_model.fit(python_train_vectorized, python_train_labels_int)\n",
        "\n",
        "predictions = python_model.predict(python_test_vectorized)\n",
        "\n",
        "python_original_results = classification_report(python_test_labels_int, predictions, output_dict=True)\n",
        "\n",
        "print(python_original_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljL_hENTCnFn"
      },
      "source": [
        "### Pipeline Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Count Vectorizer"
      ],
      "metadata": {
        "id": "XFZ-Wa--Bt4r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sW-WwkH4upw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f76d56-61f2-41ec-ca4f-26111703db19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COUNT VECTORIZER\n",
            "Pipeline 1:\n",
            "{'0': {'precision': 0.6470588235294118, 'recall': 0.5454545454545454, 'f1-score': 0.5919282511210763, 'support': 121.0}, '1': {'precision': 0.6453488372093024, 'recall': 0.8740157480314961, 'f1-score': 0.7424749163879598, 'support': 127.0}, '2': {'precision': 0.3333333333333333, 'recall': 0.15151515151515152, 'f1-score': 0.20833333333333334, 'support': 33.0}, '3': {'precision': 0.40425531914893614, 'recall': 0.3958333333333333, 'f1-score': 0.4, 'support': 48.0}, '4': {'precision': 0.6, 'recall': 0.5454545454545454, 'f1-score': 0.5714285714285714, 'support': 77.0}, 'accuracy': 0.5985221674876847, 'macro avg': {'precision': 0.5259992626441967, 'recall': 0.5024546647578143, 'f1-score': 0.5028330144541882, 'support': 406.0}, 'weighted avg': {'precision': 0.5833932888960325, 'recall': 0.5985221674876847, 'f1-score': 0.581262642283057, 'support': 406.0}}\n",
            "Pipeline 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.6702127659574468, 'recall': 0.5206611570247934, 'f1-score': 0.586046511627907, 'support': 121.0}, '1': {'precision': 0.7194244604316546, 'recall': 0.7874015748031497, 'f1-score': 0.7518796992481203, 'support': 127.0}, '2': {'precision': 0.2631578947368421, 'recall': 0.30303030303030304, 'f1-score': 0.28169014084507044, 'support': 33.0}, '3': {'precision': 0.423728813559322, 'recall': 0.5208333333333334, 'f1-score': 0.4672897196261682, 'support': 48.0}, '4': {'precision': 0.5657894736842105, 'recall': 0.5584415584415584, 'f1-score': 0.5620915032679739, 'support': 77.0}, 'accuracy': 0.5935960591133005, 'macro avg': {'precision': 0.5284626816738952, 'recall': 0.5380735853266276, 'f1-score': 0.5297995149230479, 'support': 406.0}, 'weighted avg': {'precision': 0.603575453710637, 'recall': 0.5935960591133005, 'f1-score': 0.5945987109681414, 'support': 406.0}}\n",
            "Pipeline 3:\n",
            "{'0': {'precision': 0.6090225563909775, 'recall': 0.6694214876033058, 'f1-score': 0.6377952755905512, 'support': 121.0}, '1': {'precision': 0.782258064516129, 'recall': 0.7637795275590551, 'f1-score': 0.7729083665338645, 'support': 127.0}, '2': {'precision': 0.1724137931034483, 'recall': 0.15151515151515152, 'f1-score': 0.16129032258064516, 'support': 33.0}, '3': {'precision': 0.40540540540540543, 'recall': 0.3125, 'f1-score': 0.35294117647058826, 'support': 48.0}, '4': {'precision': 0.5662650602409639, 'recall': 0.6103896103896104, 'f1-score': 0.5875, 'support': 77.0}, 'accuracy': 0.603448275862069, 'macro avg': {'precision': 0.5070729759313848, 'recall': 0.5015211554134246, 'f1-score': 0.5024870282351299, 'support': 406.0}, 'weighted avg': {'precision': 0.5955419403627689, 'recall': 0.603448275862069, 'f1-score': 0.5981129261379483, 'support': 406.0}}\n",
            "Pipeline 4:\n",
            "{'0': {'precision': 0.664, 'recall': 0.6859504132231405, 'f1-score': 0.6747967479674797, 'support': 121.0}, '1': {'precision': 0.7637795275590551, 'recall': 0.7637795275590551, 'f1-score': 0.7637795275590551, 'support': 127.0}, '2': {'precision': 0.14285714285714285, 'recall': 0.15151515151515152, 'f1-score': 0.14705882352941177, 'support': 33.0}, '3': {'precision': 0.40476190476190477, 'recall': 0.3541666666666667, 'f1-score': 0.37777777777777777, 'support': 48.0}, '4': {'precision': 0.5584415584415584, 'recall': 0.5584415584415584, 'f1-score': 0.5584415584415584, 'support': 77.0}, 'accuracy': 0.603448275862069, 'macro avg': {'precision': 0.5067680267239323, 'recall': 0.5027706634811145, 'f1-score': 0.5043708870550565, 'support': 406.0}, 'weighted avg': {'precision': 0.6021843771991555, 'recall': 0.603448275862069, 'f1-score': 0.6025534015119924, 'support': 406.0}}\n",
            "Pipeline 5:\n",
            "{'0': {'precision': 0.5606060606060606, 'recall': 0.6115702479338843, 'f1-score': 0.5849802371541502, 'support': 121.0}, '1': {'precision': 0.7266187050359713, 'recall': 0.7952755905511811, 'f1-score': 0.7593984962406015, 'support': 127.0}, '2': {'precision': 0.21739130434782608, 'recall': 0.15151515151515152, 'f1-score': 0.17857142857142858, 'support': 33.0}, '3': {'precision': 0.3235294117647059, 'recall': 0.22916666666666666, 'f1-score': 0.2682926829268293, 'support': 48.0}, '4': {'precision': 0.44871794871794873, 'recall': 0.45454545454545453, 'f1-score': 0.45161290322580644, 'support': 77.0}, 'accuracy': 0.5566502463054187, 'macro avg': {'precision': 0.4553726860945025, 'recall': 0.4484146222424677, 'f1-score': 0.44857114962376315, 'support': 406.0}, 'weighted avg': {'precision': 0.5353904328383444, 'recall': 0.5566502463054187, 'f1-score': 0.5437717172166024, 'support': 406.0}}\n"
          ]
        }
      ],
      "source": [
        "print(\"COUNT VECTORIZER\")\n",
        "\n",
        "print(\"Pipeline 1:\")\n",
        "print(use_pipeline(pipelineMNB_count, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 2:\")\n",
        "print(use_pipeline(pipelineCNB_count, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 3:\")\n",
        "print(use_pipeline(pipelineLR_count, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 4:\")\n",
        "print(use_pipeline(pipelineSVC_count, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 5:\")\n",
        "print(use_pipeline(pipelineRF_count, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TFIDF"
      ],
      "metadata": {
        "id": "LNlbXMiXB4Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TFIDF\")\n",
        "\n",
        "print(\"Pipeline 6:\")\n",
        "print(use_pipeline(pipelineMNB_tfidf, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 7:\")\n",
        "print(use_pipeline(pipelineCNB_tfidf, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 8:\")\n",
        "print(use_pipeline(pipelineLR_tfidf, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 9:\")\n",
        "print(use_pipeline(pipelineSVC_tfidf, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 10:\")\n",
        "print(use_pipeline(pipelineRF_tfidf, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int))"
      ],
      "metadata": {
        "id": "HMy-wJLLBsiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a87cec-347a-4797-97dd-13b833dc09ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF\n",
            "Pipeline 6:\n",
            "{'0': {'precision': 0.5337837837837838, 'recall': 0.6528925619834711, 'f1-score': 0.587360594795539, 'support': 121.0}, '1': {'precision': 0.5409090909090909, 'recall': 0.937007874015748, 'f1-score': 0.6858789625360231, 'support': 127.0}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 33.0}, '3': {'precision': 0.875, 'recall': 0.14583333333333334, 'f1-score': 0.25, 'support': 48.0}, '4': {'precision': 0.6896551724137931, 'recall': 0.2597402597402597, 'f1-score': 0.37735849056603776, 'support': 77.0}, 'accuracy': 0.5541871921182266, 'macro avg': {'precision': 0.5278696094213335, 'recall': 0.39909480581456236, 'f1-score': 0.38011960957951996, 'support': 406.0}, 'weighted avg': {'precision': 0.5625289178796907, 'recall': 0.5541871921182266, 'f1-score': 0.4907238029209854, 'support': 406.0}}\n",
            "Pipeline 7:\n",
            "{'0': {'precision': 0.6702127659574468, 'recall': 0.5206611570247934, 'f1-score': 0.586046511627907, 'support': 121.0}, '1': {'precision': 0.6818181818181818, 'recall': 0.8267716535433071, 'f1-score': 0.7473309608540926, 'support': 127.0}, '2': {'precision': 0.2857142857142857, 'recall': 0.30303030303030304, 'f1-score': 0.29411764705882354, 'support': 33.0}, '3': {'precision': 0.43636363636363634, 'recall': 0.5, 'f1-score': 0.46601941747572817, 'support': 48.0}, '4': {'precision': 0.6029411764705882, 'recall': 0.5324675324675324, 'f1-score': 0.5655172413793104, 'support': 77.0}, 'accuracy': 0.5985221674876847, 'macro avg': {'precision': 0.5354100092648278, 'recall': 0.5365861292131873, 'f1-score': 0.5318063556791722, 'support': 406.0}, 'weighted avg': {'precision': 0.6021850993448803, 'recall': 0.5985221674876847, 'f1-score': 0.5946854726931762, 'support': 406.0}}\n",
            "Pipeline 8:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.5616438356164384, 'recall': 0.6776859504132231, 'f1-score': 0.6142322097378277, 'support': 121.0}, '1': {'precision': 0.6870748299319728, 'recall': 0.7952755905511811, 'f1-score': 0.7372262773722628, 'support': 127.0}, '2': {'precision': 0.3333333333333333, 'recall': 0.12121212121212122, 'f1-score': 0.17777777777777778, 'support': 33.0}, '3': {'precision': 0.43333333333333335, 'recall': 0.2708333333333333, 'f1-score': 0.3333333333333333, 'support': 48.0}, '4': {'precision': 0.5915492957746479, 'recall': 0.5454545454545454, 'f1-score': 0.5675675675675675, 'support': 77.0}, 'accuracy': 0.5960591133004927, 'macro avg': {'precision': 0.5213869255979452, 'recall': 0.48209230819288074, 'f1-score': 0.4860274331577538, 'support': 406.0}, 'weighted avg': {'precision': 0.5728243923290579, 'recall': 0.5960591133004927, 'f1-score': 0.5751704531377436, 'support': 406.0}}\n",
            "Pipeline 9:\n",
            "{'0': {'precision': 0.6638655462184874, 'recall': 0.6528925619834711, 'f1-score': 0.6583333333333333, 'support': 121.0}, '1': {'precision': 0.7862595419847328, 'recall': 0.8110236220472441, 'f1-score': 0.7984496124031008, 'support': 127.0}, '2': {'precision': 0.27586206896551724, 'recall': 0.24242424242424243, 'f1-score': 0.25806451612903225, 'support': 33.0}, '3': {'precision': 0.4, 'recall': 0.375, 'f1-score': 0.3870967741935484, 'support': 48.0}, '4': {'precision': 0.573170731707317, 'recall': 0.6103896103896104, 'f1-score': 0.5911949685534591, 'support': 77.0}, 'accuracy': 0.6280788177339901, 'macro avg': {'precision': 0.539831577775211, 'recall': 0.5383460073689136, 'f1-score': 0.5386278409224947, 'support': 406.0}, 'weighted avg': {'precision': 0.6222174569995653, 'recall': 0.6280788177339901, 'f1-score': 0.6248281302480094, 'support': 406.0}}\n",
            "Pipeline 10:\n",
            "{'0': {'precision': 0.5735294117647058, 'recall': 0.6446280991735537, 'f1-score': 0.6070038910505836, 'support': 121.0}, '1': {'precision': 0.6666666666666666, 'recall': 0.8031496062992126, 'f1-score': 0.7285714285714285, 'support': 127.0}, '2': {'precision': 0.1875, 'recall': 0.09090909090909091, 'f1-score': 0.12244897959183673, 'support': 33.0}, '3': {'precision': 0.30434782608695654, 'recall': 0.14583333333333334, 'f1-score': 0.19718309859154928, 'support': 48.0}, '4': {'precision': 0.48717948717948717, 'recall': 0.4935064935064935, 'f1-score': 0.49032258064516127, 'support': 77.0}, 'accuracy': 0.5615763546798029, 'macro avg': {'precision': 0.44384467833956326, 'recall': 0.4356053246443368, 'f1-score': 0.4291059956901119, 'support': 406.0}, 'weighted avg': {'precision': 0.523085570579287, 'recall': 0.5615763546798029, 'f1-score': 0.5350652364884099, 'support': 406.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best Pipeline"
      ],
      "metadata": {
        "id": "X5pNp7P9kdN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pipeline 9:\")\n",
        "python_pipeline_results = use_pipeline(pipelineSVC_tfidf, python_train_combo, python_train_labels_int, python_test_combo, python_test_labels_int)"
      ],
      "metadata": {
        "id": "SsWObP3iItOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54a6cf45-5de7-4e74-d46d-cd0b1303e2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline 9:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Grid Search Optimization\n",
        "Interestingly enough, when we started to tune the parameters, our accuracy dropped significabtly. We believe this is due to some heavy overfitting. Below, we included the results of our grid searches, but they did not help much for some reason. Nevertheless, we recorded the data as we wanted to compare it with our previous results."
      ],
      "metadata": {
        "id": "RwcCGcHgkCfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'tfidf__max_df': [0.9],\n",
        "    'tfidf__min_df': [1, 2],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__use_idf': [True],\n",
        "    'clf__C': [1, 10],\n",
        "    'clf__max_iter': [1000, 5000],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipelineSVC_tfidf, parameters, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(python_train_combo, python_train_labels_int)\n",
        "\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best score:\", grid_search.best_score_)\n",
        "\n",
        "python_tuned_results = classification_report(python_test_labels_int, grid_search.best_estimator_.predict(python_test_combo), output_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M8K24RSkDE9",
        "outputId": "888717d5-c5ac-426f-caeb-bfe0384f4d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'clf__C': 1, 'clf__max_iter': 1000, 'tfidf__max_df': 0.9, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__use_idf': True}\n",
            "Best score: 0.4309865116541565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQVGEn_cgW2B"
      },
      "source": [
        "## 2B: Pharo Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xiGe6ot1NZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103e6f78-255c-47ec-cf82-c81162052049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Loading Pharo for processing\n",
        "\n",
        "pharo_labels = labels['pharo']\n",
        "\n",
        "pharo_train = ds['pharo_train'].to_pandas()\n",
        "pharo_train_labels = ds['pharo_train']['labels']\n",
        "\n",
        "pharo_test = ds['pharo_test'].to_pandas()\n",
        "pharo_test_labels = ds['pharo_test']['labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF6SU4Rqq4Vp"
      },
      "source": [
        "### Data Preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEXoEUlW07FQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "stop_words = []\n",
        "\n",
        "def preprocess_text(train, test):\n",
        "  vectorizer = CountVectorizer(lowercase = True, stop_words=stop_words)\n",
        "  train_vectorized = vectorizer.fit_transform(train)\n",
        "  test_vectorized = vectorizer.transform(test)\n",
        "  return train_vectorized, test_vectorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIh9Xp3G2t0F"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Below is another method that we had thought to implement, but didn't utilzie\n",
        "#\n",
        "\n",
        "\n",
        "# print(pharo_train_combo)\n",
        "\n",
        "# def remove_punctuation(text):\n",
        "#     import string\n",
        "#     translator = str.maketrans('', '', string.punctuation)\n",
        "#     return text.translate(translator)\n",
        "\n",
        "# pharo_train_combo = [remove_punctuation(comment) for comment in pharo_train_combo]\n",
        "# pharo_test_combo = [remove_punctuation(comment) for comment in pharo_test_combo]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmuOc72j1XRF"
      },
      "outputs": [],
      "source": [
        "pharo_train_combo = ds['pharo_train']['combo']\n",
        "pharo_train_labels_int = np.argmax(pharo_train_labels, axis=1)\n",
        "\n",
        "pharo_test_combo = ds['pharo_test']['combo']\n",
        "pharo_test_labels_int = np.argmax(pharo_test_labels, axis=1)\n",
        "\n",
        "pharo_train_vectorized, pharo_test_vectorized = preprocess_text(pharo_train_combo, pharo_test_combo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FfKzjS61X4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac49d230-724a-4e45-c335-da6df8fd95ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pharo train:\n",
            "Data shape:  (1298, 2690)\n",
            "Labels shape:  (1298,)\n",
            "\n",
            "Pharo test:\n",
            "Data shape:  (289, 2690)\n",
            "Labels shape:  (289,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Pharo train:\")\n",
        "print(\"Data shape: \",pharo_train_vectorized.shape)\n",
        "print(\"Labels shape: \",pharo_train_labels_int.shape)\n",
        "print()\n",
        "print(\"Pharo test:\")\n",
        "print(\"Data shape: \",pharo_test_vectorized.shape)\n",
        "print(\"Labels shape: \",pharo_test_labels_int.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0PDJJII07dv"
      },
      "source": [
        "### Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCerSmrA0-rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4952147a-74d3-4ed5-80e6-8080924b841c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.6129032258064516, 'recall': 0.4418604651162791, 'f1-score': 0.5135135135135135, 'support': 43.0}, '1': {'precision': 0.7302631578947368, 'recall': 0.9327731092436975, 'f1-score': 0.8191881918819188, 'support': 119.0}, '2': {'precision': 0.6, 'recall': 0.5294117647058824, 'f1-score': 0.5625, 'support': 51.0}, '3': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1.0}, '4': {'precision': 0.6521739130434783, 'recall': 0.5357142857142857, 'f1-score': 0.5882352941176471, 'support': 28.0}, '5': {'precision': 0.7352941176470589, 'recall': 0.6410256410256411, 'f1-score': 0.684931506849315, 'support': 39.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8.0}, 'accuracy': 0.6851211072664359, 'macro avg': {'precision': 0.5472334877702465, 'recall': 0.5829693236865409, 'f1-score': 0.5478621675755802, 'support': 289.0}, 'weighted avg': {'precision': 0.6619152064103937, 'recall': 0.6851211072664359, 'f1-score': 0.6647112788377629, 'support': 289.0}}\n"
          ]
        }
      ],
      "source": [
        "pharo_model = LogisticRegression(max_iter=1000)\n",
        "pharo_model.fit(pharo_train_vectorized, pharo_train_labels_int)\n",
        "\n",
        "predictions = pharo_model.predict(pharo_test_vectorized)\n",
        "pharo_original_results = classification_report(pharo_test_labels_int, predictions, output_dict=True)\n",
        "\n",
        "print(pharo_original_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline Models"
      ],
      "metadata": {
        "id": "qB0IpF-a7g6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and Testing"
      ],
      "metadata": {
        "id": "4hl1ORZa8quH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Count Vectorizer"
      ],
      "metadata": {
        "id": "YfZaHv7VCCXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"COUNT VECTORIZER\")\n",
        "\n",
        "print(\"Pipeline 1:\")\n",
        "print(use_pipeline(pipelineMNB_count, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 2:\")\n",
        "print(use_pipeline(pipelineCNB_count, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 3:\")\n",
        "print(use_pipeline(pipelineLR_count, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 4:\")\n",
        "print(use_pipeline(pipelineSVC_count, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 5:\")\n",
        "print(use_pipeline(pipelineRF_count, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))"
      ],
      "metadata": {
        "id": "YC7PCCg2CBXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e95954-c467-4651-a4ec-a79f638fac5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COUNT VECTORIZER\n",
            "Pipeline 1:\n",
            "{'0': {'precision': 0.43137254901960786, 'recall': 0.5116279069767442, 'f1-score': 0.46808510638297873, 'support': 43.0}, '1': {'precision': 0.7829457364341085, 'recall': 0.8487394957983193, 'f1-score': 0.8145161290322581, 'support': 119.0}, '2': {'precision': 0.46875, 'recall': 0.5882352941176471, 'f1-score': 0.5217391304347826, 'support': 51.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '4': {'precision': 0.7, 'recall': 0.25, 'f1-score': 0.3684210526315789, 'support': 28.0}, '5': {'precision': 0.6, 'recall': 0.5384615384615384, 'f1-score': 0.5675675675675675, 'support': 39.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8.0}, 'accuracy': 0.6262975778546713, 'macro avg': {'precision': 0.4261526122076738, 'recall': 0.39100917647917843, 'f1-score': 0.3914755694355951, 'support': 289.0}, 'weighted avg': {'precision': 0.6180823953062354, 'recall': 0.6262975778546713, 'f1-score': 0.6093934228038065, 'support': 289.0}}\n",
            "Pipeline 2:\n",
            "{'0': {'precision': 0.4576271186440678, 'recall': 0.627906976744186, 'f1-score': 0.5294117647058824, 'support': 43.0}, '1': {'precision': 0.8547008547008547, 'recall': 0.8403361344537815, 'f1-score': 0.847457627118644, 'support': 119.0}, '2': {'precision': 0.5454545454545454, 'recall': 0.47058823529411764, 'f1-score': 0.5052631578947369, 'support': 51.0}, '3': {'precision': 0.3333333333333333, 'recall': 1.0, 'f1-score': 0.5, 'support': 1.0}, '4': {'precision': 0.5454545454545454, 'recall': 0.42857142857142855, 'f1-score': 0.48, 'support': 28.0}, '5': {'precision': 0.5, 'recall': 0.48717948717948717, 'f1-score': 0.4935064935064935, 'support': 39.0}, '6': {'precision': 0.3333333333333333, 'recall': 0.25, 'f1-score': 0.2857142857142857, 'support': 8.0}, 'accuracy': 0.6401384083044983, 'macro avg': {'precision': 0.5099862472743829, 'recall': 0.586368894606143, 'f1-score': 0.5201933327057203, 'support': 289.0}, 'weighted avg': {'precision': 0.6469836571003658, 'recall': 0.6401384083044983, 'f1-score': 0.6396299380434972, 'support': 289.0}}\n",
            "Pipeline 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.6129032258064516, 'recall': 0.4418604651162791, 'f1-score': 0.5135135135135135, 'support': 43.0}, '1': {'precision': 0.7302631578947368, 'recall': 0.9327731092436975, 'f1-score': 0.8191881918819188, 'support': 119.0}, '2': {'precision': 0.6, 'recall': 0.5294117647058824, 'f1-score': 0.5625, 'support': 51.0}, '3': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1.0}, '4': {'precision': 0.6521739130434783, 'recall': 0.5357142857142857, 'f1-score': 0.5882352941176471, 'support': 28.0}, '5': {'precision': 0.7352941176470589, 'recall': 0.6410256410256411, 'f1-score': 0.684931506849315, 'support': 39.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8.0}, 'accuracy': 0.6851211072664359, 'macro avg': {'precision': 0.5472334877702465, 'recall': 0.5829693236865409, 'f1-score': 0.5478621675755802, 'support': 289.0}, 'weighted avg': {'precision': 0.6619152064103937, 'recall': 0.6851211072664359, 'f1-score': 0.6647112788377629, 'support': 289.0}}\n",
            "Pipeline 4:\n",
            "{'0': {'precision': 0.5833333333333334, 'recall': 0.4883720930232558, 'f1-score': 0.5316455696202531, 'support': 43.0}, '1': {'precision': 0.8106060606060606, 'recall': 0.8991596638655462, 'f1-score': 0.852589641434263, 'support': 119.0}, '2': {'precision': 0.5853658536585366, 'recall': 0.47058823529411764, 'f1-score': 0.5217391304347826, 'support': 51.0}, '3': {'precision': 0.5, 'recall': 1.0, 'f1-score': 0.6666666666666666, 'support': 1.0}, '4': {'precision': 0.6071428571428571, 'recall': 0.6071428571428571, 'f1-score': 0.6071428571428571, 'support': 28.0}, '5': {'precision': 0.6136363636363636, 'recall': 0.6923076923076923, 'f1-score': 0.6506024096385542, 'support': 39.0}, '6': {'precision': 0.5, 'recall': 0.375, 'f1-score': 0.42857142857142855, 'support': 8.0}, 'accuracy': 0.6920415224913494, 'macro avg': {'precision': 0.6000120669110217, 'recall': 0.6475100773762099, 'f1-score': 0.6084225290726865, 'support': 289.0}, 'weighted avg': {'precision': 0.6810758867261525, 'recall': 0.6920415224913494, 'f1-score': 0.6830323686770373, 'support': 289.0}}\n",
            "Pipeline 5:\n",
            "{'0': {'precision': 0.5714285714285714, 'recall': 0.18604651162790697, 'f1-score': 0.2807017543859649, 'support': 43.0}, '1': {'precision': 0.6790123456790124, 'recall': 0.9243697478991597, 'f1-score': 0.7829181494661922, 'support': 119.0}, '2': {'precision': 0.4745762711864407, 'recall': 0.5490196078431373, 'f1-score': 0.509090909090909, 'support': 51.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '4': {'precision': 0.7391304347826086, 'recall': 0.6071428571428571, 'f1-score': 0.6666666666666666, 'support': 28.0}, '5': {'precision': 0.8064516129032258, 'recall': 0.6410256410256411, 'f1-score': 0.7142857142857143, 'support': 39.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8.0}, 'accuracy': 0.6505190311418685, 'macro avg': {'precision': 0.46722846228283704, 'recall': 0.4153720522198146, 'f1-score': 0.42195188484220675, 'support': 289.0}, 'weighted avg': {'precision': 0.6288046803282988, 'recall': 0.6505190311418685, 'f1-score': 0.6149649865485095, 'support': 289.0}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TFIDF"
      ],
      "metadata": {
        "id": "w4q7EDI6CD_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMwS61dUwVRt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c964b9b-dc6c-4fbf-b51e-b119fc5de240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF\n",
            "Pipeline 6:\n",
            "{'0': {'precision': 0.42857142857142855, 'recall': 0.13953488372093023, 'f1-score': 0.21052631578947367, 'support': 43.0}, '1': {'precision': 0.5345622119815668, 'recall': 0.9747899159663865, 'f1-score': 0.6904761904761905, 'support': 119.0}, '2': {'precision': 0.4878048780487805, 'recall': 0.39215686274509803, 'f1-score': 0.43478260869565216, 'support': 51.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 28.0}, '5': {'precision': 0.8823529411764706, 'recall': 0.38461538461538464, 'f1-score': 0.5357142857142857, 'support': 39.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8.0}, 'accuracy': 0.5432525951557093, 'macro avg': {'precision': 0.33332735139689235, 'recall': 0.27015672100682847, 'f1-score': 0.2673570572393717, 'support': 289.0}, 'weighted avg': {'precision': 0.48903559910293437, 'recall': 0.5432525951557093, 'f1-score': 0.46465767623511917, 'support': 289.0}}\n",
            "Pipeline 7:\n",
            "{'0': {'precision': 0.4727272727272727, 'recall': 0.6046511627906976, 'f1-score': 0.5306122448979592, 'support': 43.0}, '1': {'precision': 0.853448275862069, 'recall': 0.8319327731092437, 'f1-score': 0.8425531914893617, 'support': 119.0}, '2': {'precision': 0.5471698113207547, 'recall': 0.5686274509803921, 'f1-score': 0.5576923076923077, 'support': 51.0}, '3': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '4': {'precision': 0.5652173913043478, 'recall': 0.4642857142857143, 'f1-score': 0.5098039215686274, 'support': 28.0}, '5': {'precision': 0.5263157894736842, 'recall': 0.5128205128205128, 'f1-score': 0.5194805194805194, 'support': 39.0}, '6': {'precision': 0.6666666666666666, 'recall': 0.25, 'f1-score': 0.36363636363636365, 'support': 8.0}, 'accuracy': 0.657439446366782, 'macro avg': {'precision': 0.6616493153363993, 'recall': 0.6046168019980801, 'f1-score': 0.6176826498235913, 'support': 289.0}, 'weighted avg': {'precision': 0.6660173495209211, 'recall': 0.657439446366782, 'f1-score': 0.6573211245083277, 'support': 289.0}}\n",
            "Pipeline 8:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0': {'precision': 0.55, 'recall': 0.2558139534883721, 'f1-score': 0.3492063492063492, 'support': 43.0}, '1': {'precision': 0.6098901098901099, 'recall': 0.9327731092436975, 'f1-score': 0.7375415282392026, 'support': 119.0}, '2': {'precision': 0.5384615384615384, 'recall': 0.5490196078431373, 'f1-score': 0.5436893203883495, 'support': 51.0}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1.0}, '4': {'precision': 0.6666666666666666, 'recall': 0.2857142857142857, 'f1-score': 0.4, 'support': 28.0}, '5': {'precision': 0.8260869565217391, 'recall': 0.48717948717948717, 'f1-score': 0.6129032258064516, 'support': 39.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8.0}, 'accuracy': 0.6124567474048442, 'macro avg': {'precision': 0.4558721816485792, 'recall': 0.3586429204955685, 'f1-score': 0.3776200605200504, 'support': 289.0}, 'weighted avg': {'precision': 0.604057160932443, 'recall': 0.6124567474048442, 'f1-score': 0.5730612319120953, 'support': 289.0}}\n",
            "Pipeline 9:\n",
            "{'0': {'precision': 0.6097560975609756, 'recall': 0.5813953488372093, 'f1-score': 0.5952380952380952, 'support': 43.0}, '1': {'precision': 0.828125, 'recall': 0.8907563025210085, 'f1-score': 0.8582995951417004, 'support': 119.0}, '2': {'precision': 0.5769230769230769, 'recall': 0.5882352941176471, 'f1-score': 0.5825242718446602, 'support': 51.0}, '3': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '4': {'precision': 0.64, 'recall': 0.5714285714285714, 'f1-score': 0.6037735849056604, 'support': 28.0}, '5': {'precision': 0.6153846153846154, 'recall': 0.6153846153846154, 'f1-score': 0.6153846153846154, 'support': 39.0}, '6': {'precision': 0.3333333333333333, 'recall': 0.125, 'f1-score': 0.18181818181818182, 'support': 8.0}, 'accuracy': 0.7024221453287197, 'macro avg': {'precision': 0.657646017600286, 'recall': 0.624600018898436, 'f1-score': 0.6338626206189877, 'support': 289.0}, 'weighted avg': {'precision': 0.6912668885289466, 'recall': 0.7024221453287197, 'f1-score': 0.6948160332632598, 'support': 289.0}}\n",
            "Pipeline 10:\n",
            "{'0': {'precision': 0.75, 'recall': 0.20930232558139536, 'f1-score': 0.32727272727272727, 'support': 43.0}, '1': {'precision': 0.7115384615384616, 'recall': 0.9327731092436975, 'f1-score': 0.8072727272727273, 'support': 119.0}, '2': {'precision': 0.5230769230769231, 'recall': 0.6666666666666666, 'f1-score': 0.5862068965517241, 'support': 51.0}, '3': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '4': {'precision': 0.72, 'recall': 0.6428571428571429, 'f1-score': 0.6792452830188679, 'support': 28.0}, '5': {'precision': 0.8333333333333334, 'recall': 0.6410256410256411, 'f1-score': 0.7246376811594203, 'support': 39.0}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8.0}, 'accuracy': 0.6851211072664359, 'macro avg': {'precision': 0.6482783882783882, 'recall': 0.584660697910649, 'f1-score': 0.5892336164679238, 'support': 289.0}, 'weighted avg': {'precision': 0.682560553633218, 'recall': 0.6851211072664359, 'f1-score': 0.6516071662009185, 'support': 289.0}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"TFIDF\")\n",
        "\n",
        "print(\"Pipeline 6:\")\n",
        "print(use_pipeline(pipelineMNB_tfidf, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 7:\")\n",
        "print(use_pipeline(pipelineCNB_tfidf, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 8:\")\n",
        "print(use_pipeline(pipelineLR_tfidf, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 9:\")\n",
        "print(use_pipeline(pipelineSVC_tfidf, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))\n",
        "\n",
        "print(\"Pipeline 10:\")\n",
        "print(use_pipeline(pipelineRF_tfidf, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Best Pipeline"
      ],
      "metadata": {
        "id": "KzNjB0zIvOR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pipeline 9:\")\n",
        "pharo_pipeline_results = use_pipeline(pipelineSVC_tfidf, pharo_train_combo, pharo_train_labels_int, pharo_test_combo, pharo_test_labels_int)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs3JWJaavNRn",
        "outputId": "417461f9-50e9-49de-d5db-acf24359f377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline 9:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Grid Search Optimization"
      ],
      "metadata": {
        "id": "VdkvQRJHwaw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'tfidf__max_df': [0.9],\n",
        "    'tfidf__min_df': [1, 2],\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__use_idf': [True],\n",
        "    'clf__C': [1, 10],\n",
        "    'clf__max_iter': [1000, 5000],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipelineSVC_tfidf, parameters, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(pharo_train_combo, pharo_train_labels_int)\n",
        "\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best score:\", grid_search.best_score_)\n",
        "\n",
        "pharo_tuned_results = classification_report(pharo_test_labels_int, grid_search.best_estimator_.predict(pharo_test_combo), output_dict=True)\n",
        "\n",
        "print(pharo_tuned_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og6z3Q2awZA9",
        "outputId": "801af245-68fc-4231-9ad8-687c1b7bc4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Best parameters:  {'clf__C': 1, 'clf__max_iter': 1000, 'tfidf__max_df': 0.9, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__use_idf': True}\n",
            "Best score: 0.4916008316008316\n",
            "{'0': {'precision': 0.4883720930232558, 'recall': 0.4883720930232558, 'f1-score': 0.4883720930232558, 'support': 43.0}, '1': {'precision': 0.7794117647058824, 'recall': 0.8907563025210085, 'f1-score': 0.8313725490196079, 'support': 119.0}, '2': {'precision': 0.543859649122807, 'recall': 0.6078431372549019, 'f1-score': 0.5740740740740741, 'support': 51.0}, '3': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1.0}, '4': {'precision': 0.65, 'recall': 0.4642857142857143, 'f1-score': 0.5416666666666666, 'support': 28.0}, '5': {'precision': 0.7419354838709677, 'recall': 0.5897435897435898, 'f1-score': 0.6571428571428571, 'support': 39.0}, '6': {'precision': 1.0, 'recall': 0.125, 'f1-score': 0.2222222222222222, 'support': 8.0}, 'accuracy': 0.6782006920415224, 'macro avg': {'precision': 0.7433684272461304, 'recall': 0.5951429766897814, 'f1-score': 0.6164072088783834, 'support': 289.0}, 'weighted avg': {'precision': 0.6838142767343629, 'recall': 0.6782006920415224, 'f1-score': 0.6670731037513044, 'support': 289.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Results"
      ],
      "metadata": {
        "id": "lQ47daeUiy51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Writing results to a file\n",
        "#\n",
        "\n",
        "java_original_results_df = pd.DataFrame(java_original_results).transpose()\n",
        "java_pipeline_results_df = pd.DataFrame(java_pipeline_results).transpose()\n",
        "java_tuned_results_df = pd.DataFrame(java_tuned_results).transpose()\n",
        "\n",
        "python_original_results_df = pd.DataFrame(python_original_results).transpose()\n",
        "python_pipeline_results_df = pd.DataFrame(python_pipeline_results).transpose()\n",
        "python_tuned_results_df = pd.DataFrame(python_tuned_results).transpose()\n",
        "\n",
        "pharo_original_results_df = pd.DataFrame(pharo_original_results).transpose()\n",
        "pharo_pipeline_results_df = pd.DataFrame(pharo_pipeline_results).transpose()\n",
        "pharo_tuned_results_df = pd.DataFrame(pharo_tuned_results).transpose()\n",
        "\n",
        "\n",
        "\n",
        "csv_results = \"combined_results.csv\"\n",
        "\n",
        "#\n",
        "# ------ Java -------\n",
        "#\n",
        "with open(csv_results, 'w') as f:\n",
        "    f.write('Section 1: Java 1\\n')\n",
        "    f.write('Original Results\\n')\n",
        "\n",
        "java_original_results_df.to_csv(csv_results, index=False, mode='a')\n",
        "\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Pipeline Results\\n')\n",
        "java_pipeline_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Tuned Results\\n')\n",
        "java_tuned_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# ----- Python ------\n",
        "#\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Section 2: Python 1\\n')\n",
        "    f.write('Original Results\\n')\n",
        "\n",
        "python_original_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Pipeline Results\\n')\n",
        "\n",
        "python_pipeline_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Tuned Results\\n')\n",
        "python_tuned_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "# ----- Pharo ------\n",
        "#\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Section 3: Pharo 1\\n')\n",
        "    f.write('Original Results\\n')\n",
        "pharo_original_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Pipeline Results\\n')\n",
        "pharo_pipeline_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "with open(csv_results, 'a') as f:\n",
        "    f.write('Tuned Results\\n')\n",
        "pharo_tuned_results_df.to_csv(csv_results, index=False, mode='a', header=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZoWGNK7qw2aJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
